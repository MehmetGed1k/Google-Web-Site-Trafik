import os
import random
import asyncio
from playwright.async_api import async_playwright
import re
import difflib

# Proxy ve site dosyalarÄ±nÄ±n dizin yollarÄ±
OUTPUT_DIR = r"C:\\Users\\alone\\Desktop\\proxler"
proxies_file = os.path.join(OUTPUT_DIR, "sifresizsock.txt")
sites_file = os.path.join(OUTPUT_DIR, "sites.txt")
keywords_file = os.path.join(OUTPUT_DIR, "aranacakkelime.txt")

# User-Agent listesi
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/91.0.864.64 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Firefox/89.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
]

# Dosyadan veri okuma fonksiyonu
def read_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        return [line.strip() for line in f.readlines()]

# Sayfa kaynak kodundan IP adresini al
async def get_ip_address(page):
    try:
        # SayfanÄ±n HTML iÃ§eriÄŸini al
        content = await page.content()
        
        # IP adresini bulmak iÃ§in regex kullan
        match = re.search(r'<h2 class="text-center"><strong class="mycurrentip" id="mycurrentip" style="opacity: 1;">(.*?)</strong>', content)
        if match:
            ip_address = match.group(1)
            print(f"ğŸ“¡ Proxy'nin IP adresi: {ip_address}")
            return ip_address
        else:
            print("âŒ IP adresi bulunamadÄ±.")
            return None
    except Exception as e:
        print(f"âŒ IP adresi alÄ±nÄ±rken hata oluÅŸtu: {e}")
        return None

# Google'da arama ve en yakÄ±n sonucu bulma fonksiyonu
async def google_search_and_visit(page, keyword, site):
    clean_site = site.replace("https://", "").replace("http://", "").rstrip("/")
    search_query = f"site:{clean_site} \"{keyword}\""
    
    url = f"https://www.google.com/search?q={search_query}"
    
    for _ in range(3):  # Maksimum 3 kez dene
        try:
            print(f"ğŸ” Google'da arama yapÄ±lÄ±yor: {search_query}")
            await page.goto(url, timeout=60000)
            await page.wait_for_load_state("load")
            
            # Arama kutusunun gÃ¶rÃ¼nÃ¼r olmasÄ±nÄ± bekleyelim
            await page.wait_for_selector('input[name="q"]', timeout=5000)  # Arama kutusunun gÃ¶rÃ¼nÃ¼p gÃ¶rÃ¼nmediÄŸine bak
            search_input = await page.query_selector('input[name="q"]')
            if search_input:
                await search_input.fill(search_query)  # HÄ±zlÄ±ca doldur
                await search_input.press('Enter')  # Arama yap
                await page.wait_for_load_state('load')  # Arama sonuÃ§larÄ±nÄ±n yÃ¼klenmesini bekle
                break  # BaÅŸarÄ±yla arama yapÄ±lÄ±rsa dÃ¶ngÃ¼den Ã§Ä±k
        except Exception as e:
            print(f"âŒ Google'a eriÅŸirken hata oluÅŸtu: {e}")
            await asyncio.sleep(5)  # 5 saniye bekleyip tekrar dene

    # Arama sonuÃ§larÄ±nÄ± al
    results = await page.query_selector_all("div.tF2Cxc")
    if not results:
        print("âŒ Arama sonucu bulunamadÄ±.")
        return False

    # En iyi eÅŸleÅŸen sonucu bulmak iÃ§in metin benzerliÄŸi kontrolÃ¼ yapalÄ±m
    best_match = await find_best_match(keyword, results)
    
    if best_match:
        print(f"ğŸŒ Ziyaret edilecek site: {best_match}")
        try:
            await page.goto(best_match, timeout=60000)
            await page.wait_for_load_state("load")
            print(f"âœ… Site baÅŸarÄ±yla ziyaret edildi: {best_match}")
            
            # Sayfada belirli bir sÃ¼re bekleyin
            wait_time = random.randint(30, 90)
            print(f"â³ Sayfada bekleniyor: {wait_time} saniye...")
            await asyncio.sleep(wait_time)
            return True
        except Exception as e:
            print(f"âŒ Siteye eriÅŸirken hata oluÅŸtu: {e}")
    
    return False

# Metin benzerliÄŸi ile en iyi sonucu bulma
async def find_best_match(keyword, results):
    best_match = None
    highest_score = 0
    
    # Ä°lk 5 sonucu kontrol et
    for result in results[:5]:
        link_element = await result.query_selector("a")
        best_match = await link_element.get_attribute("href") if link_element else None
        if best_match:
            # Burada, sonuÃ§larÄ±n metin iÃ§eriÄŸi ile keyword'Ã¼ karÅŸÄ±laÅŸtÄ±rabiliriz
            result_text = await result.inner_text()  # SonuÃ§ metnini al
            similarity_score = difflib.SequenceMatcher(None, keyword, result_text).ratio()
            if similarity_score > highest_score:
                highest_score = similarity_score
                best_match = best_match

    return best_match

# Web sitesine baÄŸlanmayÄ± deneyin
async def visit_site_with_proxy(browser, page, site, proxy_ip, proxy_port):
    try:
        # Proxy'yi doÄŸru ÅŸekilde ayarla
        proxy = {
            "server": f"socks5://{proxy_ip}:{proxy_port}"
        }

        # Proxy ayarÄ± ile yeni bir context oluÅŸtur
        context = await browser.new_context(proxy=proxy)
        page = await context.new_page()

        # Siteyi aÃ§
        print(f"ğŸ”— {site} adresine baÄŸlanÄ±lÄ±yor... Proxy: {proxy_ip}:{proxy_port}")
        await page.goto(site, timeout=60000)
        await page.wait_for_load_state("load")

        # IP adresini al
        ip_address = await get_ip_address(page)
        if ip_address:
            print(f"âœ… IP adresi alÄ±ndÄ±: {ip_address}")
        else:
            print("âŒ IP adresi alÄ±namadÄ±.")

        # **10 saniye bekle**
        await asyncio.sleep(10)

        return page  # Burada page dÃ¶ndÃ¼rÃ¼lÃ¼yor
    except Exception as e:
        print(f"âŒ Proxy {proxy_ip}:{proxy_port} ile baÄŸlantÄ± hatasÄ±: {e}")
        return None

# Proxy ve site gezintisi
async def visit_sites_with_proxies():
    proxies = read_file(proxies_file)
    sites = read_file(sites_file)
    keywords = read_file(keywords_file)

    async with async_playwright() as p:
        # TarayÄ±cÄ±yÄ± baÅŸlat
        browser = await p.chromium.launch(headless=False, args=["--disable-blink-features=AutomationControlled"])

        for proxy in proxies:
            proxy_ip, proxy_port = proxy.split(":")
            print(f"\nğŸ”„ Yeni proxy kullanÄ±lÄ±yor: {proxy}")

            # Proxy ayarlarÄ±yla yeni bir context oluÅŸtur
            context = await browser.new_context(
                user_agent=random.choice(USER_AGENTS),
                viewport={'width': random.randint(1024, 1920), 'height': random.randint(768, 1080)},
                locale='en-US'
            )
            await context.add_init_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

            # Ä°lk olarak ip-adresim.net adresine baÄŸlan
            ip_site = "https://ip-adresim.net/"
            print(f"ğŸ”— IP adresini almak iÃ§in {ip_site} adresine baÄŸlanÄ±lÄ±yor...")
            page = await visit_site_with_proxy(browser, context.new_page(), ip_site, proxy_ip, proxy_port)

            # IP adresi alÄ±ndÄ±ysa, kelimeler Ã¼zerinde arama yap
            if page:
                for site in sites:
                    print(f"ğŸ” Site Ã¼zerinde arama yapÄ±lacak: {site}")
                    for keyword in keywords:
                        print(f"ğŸ” Kelime arama: {keyword}")
                        await google_search_and_visit(page, keyword, site)

            # BaÅŸarÄ± mesajÄ±
            print(f"âœ… {proxy} ile tÃ¼m iÅŸlemler baÅŸarÄ±yla tamamlandÄ±!")

            # SayfayÄ± kapat
            await page.close()

        # TarayÄ±cÄ±yÄ± kapat
        await browser.close()

# Ana fonksiyonu Ã§alÄ±ÅŸtÄ±r
asyncio.run(visit_sites_with_proxies())
